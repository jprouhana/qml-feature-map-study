{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Feature Map Comparison for Classification\n",
    "\n",
    "In quantum machine learning, the feature map — the circuit that encodes classical data into quantum states — is the most important design decision. It determines what the quantum model can learn, how expressive it is, and how well the quantum kernel aligns with the classification task.\n",
    "\n",
    "In this notebook, we compare four different quantum feature maps:\n",
    "\n",
    "1. **Angle Encoding** — simple Ry rotations, no entanglement\n",
    "2. **ZZFeatureMap** — Qiskit's entangling feature map with pairwise ZZ interactions\n",
    "3. **IQP-style** — diagonal ZZ gates interspersed with Hadamard layers\n",
    "4. **Amplitude Encoding** — encode data in state amplitudes\n",
    "\n",
    "We evaluate them on three metrics:\n",
    "- Classification accuracy (paired with a VQC)\n",
    "- Quantum kernel target alignment\n",
    "- Circuit expressibility\n",
    "\n",
    "The goal is to understand *why* one feature map works better than another for a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from src.feature_maps import (\n",
    "    build_angle_encoding, build_zz_feature_map,\n",
    "    build_iqp_feature_map, build_amplitude_encoding,\n",
    "    get_all_feature_maps\n",
    ")\n",
    "from src.kernel_analysis import (\n",
    "    compute_quantum_kernel_matrix, compute_kernel_target_alignment,\n",
    "    compare_kernel_matrices\n",
    ")\n",
    "from src.expressibility import compute_expressibility\n",
    "from src.classification import (\n",
    "    train_vqc_with_feature_map, evaluate_model,\n",
    "    compare_feature_maps_classification\n",
    ")\n",
    "from src.data_utils import load_moons, load_circles, load_iris_2d\n",
    "from src.plotting import (\n",
    "    plot_accuracy_comparison, plot_kernel_matrices,\n",
    "    plot_kernel_alignment_bars, plot_expressibility_histograms\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "RESULTS_DIR = Path('../results')\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Map Circuits\n",
    "\n",
    "Let's first look at what each feature map actually does. The key differences are in how they use entanglement and how they encode the classical features.\n",
    "\n",
    "- **Angle encoding** just does single-qubit rotations — no entanglement, so it creates product states\n",
    "- **ZZFeatureMap** adds entangling ZZ gates that create correlations between qubits based on products of features\n",
    "- **IQP-style** uses a similar diagonal-entangling approach but with a different gate structure\n",
    "- **Amplitude encoding** packs data into amplitudes, which is data-efficient but harder to prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and display all feature maps for 2 qubits\n",
    "feature_maps = get_all_feature_maps(n_qubits=2)\n",
    "\n",
    "for name, fm in feature_maps.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{name} ({fm.num_parameters} parameters, {fm.depth()} depth)\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(fm.decompose().draw(output='text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datasets\n",
    "\n",
    "We use three 2D datasets for the 2-qubit experiments. All features are scaled to $[0, \\pi]$ since quantum feature maps use rotation angles.\n",
    "\n",
    "- **make_moons**: two interleaving crescents — tests nonlinear separation\n",
    "- **make_circles**: concentric circles — tests radial separation\n",
    "- **Iris 2D**: real-world data (sepal length/width, 2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all datasets\n",
    "datasets = {\n",
    "    'make_moons': load_moons(n_samples=200),\n",
    "    'make_circles': load_circles(n_samples=200),\n",
    "    'Iris 2D': load_iris_2d(),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "for idx, (name, (X_tr, X_te, y_tr, y_te)) in enumerate(datasets.items()):\n",
    "    axes[idx].scatter(X_tr[:, 0], X_tr[:, 1], c=y_tr, cmap='coolwarm',\n",
    "                     alpha=0.7, edgecolors='k', s=40)\n",
    "    axes[idx].set_title(name)\n",
    "    axes[idx].set_xlabel('Feature 1')\n",
    "    axes[idx].set_ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'datasets.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Accuracy\n",
    "\n",
    "The most direct test: pair each feature map with the same RealAmplitudes ansatz and COBYLA optimizer, train a VQC, and compare test accuracy.\n",
    "\n",
    "This tells us how well each encoding supports learning the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run classification with each feature map on each dataset\n",
    "all_results = {}\n",
    "\n",
    "for ds_name, (X_tr, X_te, y_tr, y_te) in datasets.items():\n",
    "    print(f\"\\n--- {ds_name} ---\")\n",
    "    results = compare_feature_maps_classification(\n",
    "        feature_maps, X_tr, y_tr, X_te, y_te\n",
    "    )\n",
    "    all_results[ds_name] = results\n",
    "    \n",
    "    for fm_name, acc in results.items():\n",
    "        print(f\"  {fm_name}: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy comparison bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "fm_names = list(feature_maps.keys())\n",
    "ds_names = list(datasets.keys())\n",
    "x = np.arange(len(fm_names))\n",
    "width = 0.25\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "for i, ds_name in enumerate(ds_names):\n",
    "    accs = [all_results[ds_name].get(fm, 0.5) for fm in fm_names]\n",
    "    bars = ax.bar(x + i * width, accs, width, label=ds_name,\n",
    "                  color=colors[i], alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        ax.annotate(f'{h:.2f}', xy=(bar.get_x() + bar.get_width()/2, h),\n",
    "                   xytext=(0, 3), textcoords='offset points', ha='center', fontsize=8)\n",
    "\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "ax.set_title('Classification Accuracy by Feature Map')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(fm_names, rotation=15)\n",
    "ax.legend()\n",
    "ax.set_ylim(0.5, 1.05)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'accuracy_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quantum Kernel Analysis\n",
    "\n",
    "Classification accuracy tells us *what* works, but the quantum kernel tells us *why*. The kernel matrix $K_{ij} = |\\langle\\phi(x_i)|\\phi(x_j)\\rangle|^2$ encodes the similarity structure that the quantum model sees.\n",
    "\n",
    "**Kernel target alignment** measures how well the kernel matrix matches the ideal kernel for the classification task. Higher alignment = the feature map naturally groups same-class points together.\n",
    "\n",
    "$$\\text{KTA} = \\frac{\\langle K, yy^T \\rangle_F}{\\|K\\|_F \\|yy^T\\|_F}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute kernel matrices and alignment for make_moons\n",
    "X_tr_moons = datasets['make_moons'][0]\n",
    "y_tr_moons = datasets['make_moons'][2]\n",
    "\n",
    "# use a subset for kernel computation (it's O(n^2))\n",
    "n_kernel = min(50, len(X_tr_moons))\n",
    "X_kernel = X_tr_moons[:n_kernel]\n",
    "y_kernel = y_tr_moons[:n_kernel]\n",
    "\n",
    "print(\"Computing kernel matrices...\")\n",
    "kernel_matrices = {}\n",
    "alignments = {}\n",
    "\n",
    "for name, fm in feature_maps.items():\n",
    "    print(f\"  {name}...\")\n",
    "    K = compute_quantum_kernel_matrix(fm, X_kernel)\n",
    "    kta = compute_kernel_target_alignment(K, y_kernel)\n",
    "    kernel_matrices[name] = K\n",
    "    alignments[name] = kta\n",
    "    print(f\"    KTA = {kta:.4f}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize kernel matrices\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4.5))\n",
    "\n",
    "for idx, (name, K) in enumerate(kernel_matrices.items()):\n",
    "    im = axes[idx].imshow(K, cmap='viridis', vmin=0, vmax=1)\n",
    "    axes[idx].set_title(f'{name}\\nKTA = {alignments[name]:.3f}')\n",
    "    axes[idx].set_xlabel('Sample index')\n",
    "    if idx == 0:\n",
    "        axes[idx].set_ylabel('Sample index')\n",
    "    plt.colorbar(im, ax=axes[idx], fraction=0.046)\n",
    "\n",
    "plt.suptitle('Quantum Kernel Matrices (make_moons)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'kernel_matrices.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel target alignment comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "names = list(alignments.keys())\n",
    "values = [alignments[n] for n in names]\n",
    "colors_bar = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "\n",
    "bars = ax.bar(names, values, color=colors_bar, alpha=0.85, edgecolor='black', linewidth=0.5)\n",
    "for bar, val in zip(bars, values):\n",
    "    ax.annotate(f'{val:.3f}', xy=(bar.get_x() + bar.get_width()/2, val),\n",
    "               xytext=(0, 5), textcoords='offset points', ha='center', fontsize=11)\n",
    "\n",
    "ax.set_ylabel('Kernel Target Alignment')\n",
    "ax.set_title('Kernel Target Alignment by Feature Map (make_moons)')\n",
    "ax.set_ylim(0, max(values) * 1.2)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'kernel_alignment.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Expressibility Analysis\n",
    "\n",
    "Expressibility measures how well a parameterized circuit can explore the Hilbert space. We quantify this by:\n",
    "\n",
    "1. Sampling pairs of random parameter vectors\n",
    "2. Computing the fidelity between the resulting states\n",
    "3. Comparing the fidelity distribution to the Haar random distribution\n",
    "\n",
    "A more expressible circuit has a fidelity distribution closer to the Haar distribution (KL divergence close to 0). But expressibility alone doesn't guarantee good classification — you also need the feature map to align with your specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute expressibility for each feature map\n",
    "print(\"Computing expressibility (this takes a moment)...\")\n",
    "expressibility_results = {}\n",
    "\n",
    "for name, fm in feature_maps.items():\n",
    "    print(f\"  {name}...\")\n",
    "    expr_data = compute_expressibility(fm, n_samples=500)\n",
    "    expressibility_results[name] = expr_data\n",
    "    print(f\"    KL divergence from Haar: {expr_data['kl_divergence']:.4f}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fidelity distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, data) in enumerate(expressibility_results.items()):\n",
    "    fidelities = data['fidelities']\n",
    "    axes[idx].hist(fidelities, bins=30, density=True, alpha=0.7,\n",
    "                  color=colors_bar[idx], edgecolor='black', linewidth=0.5,\n",
    "                  label='Sampled')\n",
    "    \n",
    "    # plot Haar random reference (for 2 qubits: P(F) = 3(1-F)^2)\n",
    "    f_range = np.linspace(0, 1, 100)\n",
    "    n_q = 2\n",
    "    dim = 2 ** n_q\n",
    "    haar_pdf = (dim - 1) * (1 - f_range) ** (dim - 2)\n",
    "    axes[idx].plot(f_range, haar_pdf, 'k--', linewidth=2, label='Haar random')\n",
    "    \n",
    "    axes[idx].set_title(f\"{name}\\nKL = {data['kl_divergence']:.4f}\")\n",
    "    axes[idx].set_xlabel('Fidelity')\n",
    "    axes[idx].set_ylabel('Density')\n",
    "    axes[idx].legend(fontsize=9)\n",
    "\n",
    "plt.suptitle('Expressibility: Fidelity Distributions vs Haar Random', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'expressibility.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Circuit Resources\n",
    "\n",
    "Practical considerations matter too. More complex feature maps might give better accuracy, but they also require more gates and deeper circuits — which means more noise on real hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit resource comparison\n",
    "print(f\"{'Feature Map':<22} {'Depth':>6} {'Gates':>6} {'CX Gates':>9} {'Params':>7}\")\n",
    "print('=' * 55)\n",
    "\n",
    "resource_data = {}\n",
    "for name, fm in feature_maps.items():\n",
    "    decomposed = fm.decompose()\n",
    "    ops = decomposed.count_ops()\n",
    "    cx_count = ops.get('cx', 0)\n",
    "    total_gates = sum(ops.values())\n",
    "    depth = decomposed.depth()\n",
    "    n_params = fm.num_parameters\n",
    "    \n",
    "    resource_data[name] = {\n",
    "        'depth': depth, 'total_gates': total_gates,\n",
    "        'cx_gates': cx_count, 'params': n_params\n",
    "    }\n",
    "    print(f\"{name:<22} {depth:>6} {total_gates:>6} {cx_count:>9} {n_params:>7}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation: KTA vs Accuracy\n",
    "\n",
    "An important practical question: can kernel target alignment predict which feature map will give the best accuracy *without* having to train a full VQC? If so, it's a much cheaper way to do feature map selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot: KTA vs accuracy\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "for i, (name, kta) in enumerate(alignments.items()):\n",
    "    acc = all_results['make_moons'].get(name, 0.5)\n",
    "    ax.scatter(kta, acc, s=150, color=colors_bar[i], edgecolors='black',\n",
    "              linewidth=1.5, zorder=5, label=name)\n",
    "\n",
    "ax.set_xlabel('Kernel Target Alignment')\n",
    "ax.set_ylabel('Classification Accuracy')\n",
    "ax.set_title('KTA vs Classification Accuracy (make_moons)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'kta_vs_accuracy.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"Higher KTA generally correlates with higher accuracy.\")\n",
    "print(\"This suggests KTA is a useful proxy for feature map selection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What we learned:\n",
    "\n",
    "1. **Feature map choice matters a lot** — the difference between the best and worst encoding can be 10-15% accuracy on these datasets.\n",
    "\n",
    "2. **Entanglement helps** — ZZFeatureMap and IQP-style encodings consistently outperform angle encoding, because they can represent nonlinear relationships between features.\n",
    "\n",
    "3. **Kernel target alignment is predictive** — KTA correlates with classification accuracy, making it a cheap proxy for feature map selection. You can evaluate KTA without training a full VQC.\n",
    "\n",
    "4. **Expressibility isn't everything** — being able to explore more of Hilbert space doesn't automatically mean better classification. What matters is whether the feature map creates a *useful* geometry for your specific data.\n",
    "\n",
    "5. **There's a resource tradeoff** — more expressive feature maps need more gates and deeper circuits, which translates to more noise on real hardware.\n",
    "\n",
    "### Practical takeaway:\n",
    "\n",
    "When designing a QML pipeline, start by computing KTA for a few candidate feature maps on your dataset. Pick the one with the highest alignment, then verify with a full VQC training run. This is much faster than training VQCs with every possible encoding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
